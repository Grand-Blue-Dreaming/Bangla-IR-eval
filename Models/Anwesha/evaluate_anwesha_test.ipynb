{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/libindic/indic-trans.git\n",
    "# ! cd indictrans && pip install -r requirements.txt && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khanm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "e:\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-18:11:35:35,294 INFO     [iwn.py:43] Loading bengali language synsets...\n",
      "2023-12-18:11:39:40,633 INFO     [iwn.py:43] Loading bengali language synsets...\n",
      "2023-12-18:11:39:48,310 INFO     [iwn.py:43] Loading bengali language synsets...\n"
     ]
    }
   ],
   "source": [
    "from Lemmatization.lemmatizer import document_linearization\n",
    "from json import load\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from helper import read_train_data, load_train_data, load_concept_data, read_concept_data\n",
    "import lsa\n",
    "import tfidf\n",
    "import esa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatasetPath = \"../../Datasets/Anwesha/Train_Dataset/\"\n",
    "testDatasetPath = \"../../Datasets/Anwesha/Test_Collection/\"\n",
    "conceptDatasetPath = \"../../Datasets/Anwesha/New_Dataset_Concepts/\"\n",
    "docs, file_paths, dids = read_train_data(testDatasetPath, save_path=True)\n",
    "c_docs, c_file_paths, c_dids = read_concept_data(conceptDatasetPath, save_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF model is saved in SavedModels directory.\n",
      "ESA model is saved in SavedModels directory.\n"
     ]
    }
   ],
   "source": [
    "TFIDF_vectorizer, tfidf_matrix = tfidf.set_up_TFIDF(docs, lemmatiser=False, save_model=True)\n",
    "c_vectorizer, c_tfidf_matrix, doc_concept_matrix = esa.set_up_ESA(c_docs, TFIDF_vectorizer, tfidf_matrix, lemmatiser=False, save_model=True)\n",
    "LSA_vectorizer, LSA_svd_transformer, svd_model, LSA_dvecs = lsa.set_up_LSA(docs, rank=600, lemmatiser=False, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs:  2182\n",
      "Literature docs:  182\n",
      "Health docs:  144\n",
      "Travel docs:  214\n",
      "News docs:  1642\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "file_names = glob.glob('D:\\\\Data\\\\repos\\\\Bangla-IR-eval\\\\Datasets\\\\Anwesha\\\\Test_Collection\\\\**\\\\*.txt', recursive=True)\n",
    "file_names.extend(glob.glob('D:\\\\Data\\\\repos\\\\Bangla-IR-eval\\\\Datasets\\\\Anwesha\\\\Train_Dataset\\\\**\\\\*.txt', recursive=True))\n",
    "files = {}\n",
    "lit_docs = []\n",
    "health_docs = []\n",
    "travel_docs = []\n",
    "news_docs = []\n",
    "for file_name in file_names:\n",
    "    doc_id = file_name.split('\\\\')[-1].split('.')[0]\n",
    "    if \"Rabindra_Rachnabali\" in file_name:\n",
    "        lit_docs.append(doc_id)\n",
    "    elif \"health\" in file_name:\n",
    "        health_docs.append(doc_id)\n",
    "    elif \"travel\" in file_name:\n",
    "        travel_docs.append(doc_id)\n",
    "    else:\n",
    "        news_docs.append(doc_id)\n",
    "    \n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        files[doc_id] = text\n",
    "        \n",
    "print(\"Total docs: \", len(files))\n",
    "print(\"Literature docs: \", len(lit_docs))\n",
    "print(\"Health docs: \", len(health_docs))\n",
    "print(\"Travel docs: \", len(travel_docs))\n",
    "print(\"News docs: \", len(news_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('../../Datasets/Anwesha/qrels-merged.json', 'r') as f:\n",
    "    qrels = json.load(f)\n",
    "\n",
    "queries = qrels.keys()\n",
    "print(len(queries))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_copy = qrels.copy()\n",
    "for q in queries:\n",
    "    doc_ids = qrels_copy[q].keys()\n",
    "    for doc_id in doc_ids:\n",
    "        if doc_id not in files.keys():\n",
    "            print(q, doc_id)\n",
    "            qrels[q].pop(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Total queries:  202\n",
      "Literature queries:  67\n",
      "Health queries:  36\n",
      "Travel queries:  40\n",
      "News queries:  134\n",
      "=================================================\n",
      "Toral qrels:  3059\n",
      "Literature qrels:  601\n",
      "Health qrels:  194\n",
      "Travel qrels:  330\n",
      "News qrels:  1934\n"
     ]
    }
   ],
   "source": [
    "lit_qrels = {}\n",
    "health_qrels = {}\n",
    "travel_qrels = {}\n",
    "news_qrels = {}\n",
    "for q in qrels.keys():\n",
    "    for doc_id in qrels[q].keys():\n",
    "        if doc_id in lit_docs:\n",
    "            if q not in lit_qrels.keys():\n",
    "                lit_qrels[q] = {}\n",
    "            lit_qrels[q][doc_id] = qrels[q][doc_id]\n",
    "        elif doc_id in health_docs:\n",
    "            if q not in health_qrels.keys():\n",
    "                health_qrels[q] = {}\n",
    "            health_qrels[q][doc_id] = qrels[q][doc_id]\n",
    "        elif doc_id in travel_docs:\n",
    "            if q not in travel_qrels.keys():\n",
    "                travel_qrels[q] = {}\n",
    "            travel_qrels[q][doc_id] = qrels[q][doc_id]\n",
    "        else:\n",
    "            if q not in news_qrels.keys():\n",
    "                news_qrels[q] = {}\n",
    "            news_qrels[q][doc_id] = qrels[q][doc_id]\n",
    "\n",
    "print(\"=================================================\")\n",
    "print(\"Total queries: \", len(qrels))\n",
    "print(\"Literature queries: \", len(lit_qrels))\n",
    "print(\"Health queries: \", len(health_qrels))\n",
    "print(\"Travel queries: \", len(travel_qrels))\n",
    "print(\"News queries: \", len(news_qrels))\n",
    "print(\"=================================================\")\n",
    "print(\"Toral qrels: \", sum([len(qrels[q]) for q in qrels.keys()]))\n",
    "print(\"Literature qrels: \", sum([len(lit_qrels[q]) for q in lit_qrels.keys()]))\n",
    "print(\"Health qrels: \", sum([len(health_qrels[q]) for q in health_qrels.keys()]))\n",
    "print(\"Travel qrels: \", sum([len(travel_qrels[q]) for q in travel_qrels.keys()]))\n",
    "print(\"News qrels: \", sum([len(news_qrels[q]) for q in news_qrels.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## literature\n",
    "with open('literature_qrels.json', 'w') as f:\n",
    "    json.dump(lit_qrels, f)\n",
    "os.mkdir('literature')\n",
    "for d in lit_docs:\n",
    "    with open('literature/'+d+'.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(files[d])\n",
    "\n",
    "## health\n",
    "with open('health_qrels.json', 'w') as f:\n",
    "    json.dump(health_qrels, f)\n",
    "os.mkdir('health')\n",
    "for d in health_docs:\n",
    "    with open('health/'+d+'.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(files[d])\n",
    "\n",
    "## travel\n",
    "with open('travel_qrels.json', 'w') as f:\n",
    "    json.dump(travel_qrels, f)\n",
    "os.mkdir('travel')\n",
    "for d in travel_docs:\n",
    "    with open('travel/'+d+'.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(files[d])\n",
    "\n",
    "## news\n",
    "with open('news_qrels.json', 'w') as f:\n",
    "    json.dump(news_qrels, f)\n",
    "os.mkdir('news')\n",
    "for d in news_docs:\n",
    "    with open('news/'+d+'.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(files[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "কালো কুমড়ো টাটকা দেখিয়ে দেব লবডঙ্কা\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10164614 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11684365 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16092093 0.         0.         0.14317849 0.\n",
      "  0.         0.20276824 0.         0.         0.         0.19512117\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.19307796 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33333333 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15643176\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2387696  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.07302498 0.         0.         0.11605387 0.         0.\n",
      "  0.         0.         0.         0.08546531 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19466474 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03576916 0.17595181 0.         0.06236457\n",
      "  0.         0.         0.         0.06834659 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14713768 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26579951 0.06343223 0.         0.         0.         0.\n",
      "  0.17985988 0.         0.         0.11051587 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07541888\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11834307 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.11247609 0.         0.\n",
      "  0.         0.         0.         0.17841537 0.         0.\n",
      "  0.12038813 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.1542261  0.13986486\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40313672\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17074267 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14988349 0.         0.         0.\n",
      "  0.         0.         0.         0.09888091 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17650255\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20181222 0.         0.         0.         0.         0.\n",
      "  0.         0.17270581 0.         0.         0.47140835 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16301162 0.         0.         0.         0.\n",
      "  0.13928041 0.         0.         0.         0.         0.24277216\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20600301 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15214336\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09925809 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22342776 0.         0.         0.29368445\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24170039 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19261061 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.22058387 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11915843 0.\n",
      "  0.         0.2599324  0.18897123 0.15207164 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24354333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12315525 0.         0.24044871\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22165158 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15592154\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16190951 0.         0.15941995 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16395381 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11548811 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1717292  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.13214395 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14512299 0.\n",
      "  0.11101854 0.         0.         0.         0.1610083  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18897019 0.         0.         0.         0.         0.\n",
      "  0.21642258 0.13392962 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21173256 0.         0.         0.         0.         0.\n",
      "  0.12683492 0.11311839 0.         0.         0.         0.13128353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05761834 0.         0.\n",
      "  0.         0.         0.1009672  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.12134378 0.10400943\n",
      "  0.         0.09870936 0.09811691 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06331708 0.\n",
      "  0.09889733 0.11596936 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.13483313 0.         0.19527193\n",
      "  0.08041937 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08851339 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.12616562\n",
      "  0.11362987 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06969887 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16062921 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07736978 0.         0.08148567\n",
      "  0.         0.         0.         0.         0.07911117 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04679895 0.         0.07186088 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14640552 0.\n",
      "  0.         0.         0.         0.         0.         0.13235182\n",
      "  0.         0.         0.         0.25360405 0.         0.\n",
      "  0.         0.         0.         0.12558012 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20768748 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10150229 0.         0.         0.\n",
      "  0.         0.13832308 0.         0.         0.0929118  0.08398197\n",
      "  0.         0.         0.         0.18747197 0.         0.\n",
      "  0.         0.         0.         0.05582131 0.22521225 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10386914 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10164926 0.09047353 0.         0.\n",
      "  0.         0.0843231  0.         0.         0.         0.\n",
      "  0.         0.13560015 0.         0.        ]]\n",
      "[[[('দেব', 0.118), ('দেখিয়ে', 0.063)], [('দেব', 0.084), ('দেখিয়ে', 0.044)], [('দেব', 0.322)], [('দেব', 0.178)], [('টাটকা', 0.089)], [('কালো', 0.147)], [('দেব', 0.112)], [('কালো', 0.123)], [('দেখিয়ে', 0.094)], [('দেখিয়ে', 0.093)]]]\n"
     ]
    }
   ],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "run_dict = {}\n",
    "for row in df_queries.itertuples():\n",
    "    q_id = row.query_id\n",
    "    q = row.query\n",
    "    A, _ = tfidf.tfidf(TFIDF_vectorizer, tfidf_matrix, q, docs)\n",
    "    k = 10\n",
    "    x = np.argsort(A[0]).T[::-1][:k]\n",
    "    index = 0\n",
    "    q_dict = {}\n",
    "    for y in x:\n",
    "        if index < k:\n",
    "            if A[0][y] > 0:\n",
    "                q_dict['D'+str(dids[y][1])] = A[0][y]\n",
    "        index = index + 1\n",
    "    run_dict[q_id] = q_dict\n",
    "run = Run(run_dict, name=\"anwesha-test\")\n",
    "qrel_df = pd.read_csv('../../Datasets/Anwesha/qrels.csv')\n",
    "qrel_df['relevance'] = qrel_df['relevance'].astype('int64')\n",
    "qrel = Qrels.from_df(\n",
    "    df=qrel_df,\n",
    "    q_id_col=\"query_id\",\n",
    "    doc_id_col=\"doc_id\",\n",
    "    score_col=\"relevance\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
