{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khanm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "e:\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-17:18:50:11,805 INFO     [iwn.py:43] Loading bengali language synsets...\n",
      "2023-12-17:18:51:50,914 INFO     [iwn.py:43] Loading bengali language synsets...\n",
      "2023-12-17:18:51:56,175 INFO     [iwn.py:43] Loading bengali language synsets...\n"
     ]
    }
   ],
   "source": [
    "from Lemmatization.lemmatizer import document_linearization\n",
    "from json import load\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from helper import read_train_data, load_train_data, load_concept_data, read_concept_data\n",
    "import lsa\n",
    "import tfidf\n",
    "import esa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Lemmatization/Lemmatized_Dataset_Title_emphasis\"\n",
    "conceptDatasetPath = \"\"\n",
    "docs, file_paths, dids = read_train_data(datasetPath)\n",
    "c_docs, c_file_paths, c_dids = read_concept_data(conceptDatasetPath, save_path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SavedModels\\\\c_TFIDF_vectorizer_lem.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m TFIDF_vectorizer, tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mset_up_TFIDF(docs, lemmatiser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m c_vectorizer, c_tfidf_matrix, doc_concept_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mesa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_up_ESA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTFIDF_vectorizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemmatiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data\\repos\\Bangla-IR-eval\\Models\\Anwesha\\esa.py:76\u001b[0m, in \u001b[0;36mset_up_ESA\u001b[1;34m(c_docs, tr_vectorizer, tr_tfidf_matrix, lemmatiser, save_model)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_model:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lemmatiser:\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_vectorizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSavedModels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc_TFIDF_vectorizer_lem.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m         sparse\u001b[38;5;241m.\u001b[39msave_npz(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_TFIDFmatrix_lem.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), c_tfidf_matrix)\n\u001b[0;32m     78\u001b[0m         sparse\u001b[38;5;241m.\u001b[39msave_npz(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_concept_matrix_lem.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), doc_concept_matrix)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\nlp\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SavedModels\\\\c_TFIDF_vectorizer_lem.pkl'"
     ]
    }
   ],
   "source": [
    "TFIDF_vectorizer, tfidf_matrix = tfidf.set_up_TFIDF(docs, lemmatiser=True, save_model=False)\n",
    "c_vectorizer, c_tfidf_matrix, doc_concept_matrix = esa.set_up_ESA(c_docs, TFIDF_vectorizer, tfidf_matrix, lemmatiser=True, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m c_vectorizer, c_tfidf_matrix, doc_concept_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mesa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_up_ESA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTFIDF_vectorizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemmatiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data\\repos\\Bangla-IR-eval\\Models\\Anwesha\\esa.py:41\u001b[0m, in \u001b[0;36mset_up_ESA\u001b[1;34m(c_docs, tr_vectorizer, tr_tfidf_matrix, lemmatiser, save_model)\u001b[0m\n\u001b[0;32m     38\u001b[0m tr_doc_concept_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((tr_doc_term_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], c_doc_term_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Returns a list of all the unique words in the vocabulary of Train Dataset.\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m tr_feature_names \u001b[38;5;241m=\u001b[39m \u001b[43mtr_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Returns a list of all the unique words in the vocabulary of Concept Dataset.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m c_feature_names \u001b[38;5;241m=\u001b[39m c_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
